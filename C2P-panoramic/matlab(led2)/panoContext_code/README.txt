This is an implementation of paper:
Y. Zhang, S. Song, P. Tan, and J. Xiao, PanoContext: A Whole-room 3D Context Model for Panoramic Scene Understanding, Proceedings of the 13th European Conference on Computer Vision (ECCV2014).
If you use any part of this implementation in your project, please cite this paper.
****************************************************************************************
If you have any problem about this work, feel free to contact:
Yinda Zhang: yindaz at cs dot princeton dot edu
OR
Jianxiong Xiao, xj at cs dot princeton dot edu

This code needs some other toolboxes as dependency, which are all included under folder "Toolbox".
****************************************************************************************
How to use:
1. Make sure all settings are correct in /Groundtruth/BEDROOMDATA.m, set project folder to your position of code and ground truth data.

2. Copy "ALL_GNDS_ROT.mat" and "GndTransform.mat" to the root folder of the dataset. You can find these two files in our published dataset: http://panocontext.cs.princeton.edu/panoContext_data.zip. These two files are for computing room alignment, which can also be generated by function:
*gndRoomProcess
*transformGndRoomsA

3. Run script_pipeline.m. It involves a list of simple functions, each of which corresponds to a major step of the system.
****************************************************************************************
Data:
1. each folder contains an panorama image and annotation json file if any. 
2. for each category, there are two data files:
"IMGLIST": contains all image names and whether an image is properly annotated.
"ALL_ANNO": contains all annotations, read from json and optimized by our code.
*name: image name
*anno3D: initial 3D annotation
*anno2D: 2D annotation
*vp: computed ground truth vanishing point
*ANNO3D: optimized 3D annotation. Especially, ANNO3D.objects3D.out_point_3 is the optimized 3D coordinates of 3D cuboid.
*****************************************************************************************
License:
This implementation is under the MIT License: http://opensource.org/licenses/MIT





 
